# Spark 시간단축

4시간 배치 작업을 1시간으로 단축하는 데에는 다양한 튜닝 기법을 적용하였습니다. 아래에서는 각각의 튜닝 기법을 어떻게 적용하여 작업 시간을 단축하였는지에 대해 디테일하게 설명해드리겠습니다.

1. 클러스터 크기: Apache Spark를 실행하는 클러스터의 크기를 충분히 크게 설정하여 작업을 더 빠르게 처리할 수 있도록 하였습니다. 이를 위해 사용 가능한 컴퓨팅 리소스를 고려하여 클러스터 구성을 선택하고, 적절한 CPU 및 메모리 할당을 수행하였습니다.
2. 파티셔닝: 데이터를 파티셔닝하여 성능을 향상시켰습니다. 파티셔닝은 데이터를 여러 개의 작은 데이터 조각으로 분할하는 것을 의미합니다. 이를 통해 병렬 처리가 가능해지며 데이터 읽기와 쓰기의 속도가 향상됩니다. 작업 전에 데이터를 적절한 방식으로 파티셔닝하여 병렬 처리를 최대한 활용하였습니다.
    1. 어떻게 파티셔닝 하였는가?  
        - 데이터 특성 파악: 먼저 작업에 사용되는 데이터의 특성을 파악하였습니다. 데이터 크기, 데이터 형식, 데이터 분포 등을 분석하여 적절한 파티셔닝 방법을 선택하였습니다.
        - 파티셔닝 방법 선택: 데이터의 특성에 따라 파티셔닝 방법을 선택하였습니다. range, hash, round-robin 등의 파티셔닝 방법을 고려하였습니다.
        - 파티션 수 결정:  데이터를 파티션으로 분할하여 병렬 처리 할 수 있도록 하였습니다. 파티션 수가 작을 경우에는 클러스터의 모든 노드에서 데이터가 처리되지 않고 일부 노드에서만 처리됩니다. 따라서 적절한 파티션 수를 선택하여 병렬 처리를 최대한 활용하였습니다.
        - 파티셔닝 적용: 선택한 파티셔닝 방법과 파티션 수를 바탕으로 데이터를 파티셔닝하여 작업에 적용하였습니다. 이를 통해 데이터의 처리를 병렬화하여 성능을 향상시켰습니다.
        - 실험과 모니터링을 통해 파티션 수를 조정합니다: 파티션 수를 결정한 후 작업을 실행하고, 작업 속도와 성능 지표를 모니터링하여 파티션 수를 조정합니다. 파티션 수가 적을 경우에는 병목 현상이 발생할 수 있고, 파티션 수가 많을 경우에는 리소스가 낭비될 수 있으므로 적절한 파티션 수를 선택하는 것이 중요합니다.
    
    예를 들어, range-based 파티셔닝을 사용하여 날짜 기반으로 데이터를 분할하였습니다. 데이터의 날짜 범위를 파악한 후, 1주일 단위로 파티션을 나누어 처리하였습니다. 이를 통해 날짜 범위가 작은 데이터를 동일한 파티션으로 묶어 병렬 처리할 수 있었습니다.
    
    또한, 데이터 크기가 큰 경우에는 hash-based 파티셔닝을 사용하여 데이터를 분할하였습니다. 이를 통해 데이터를 여러 개의 작은 파티션으로 분할하여 병렬 처리를 최대한 활용할 수 있었습니다.
    
3. 캐싱: 작업 중에 반복적으로 사용되는 데이터를 캐싱하여 작업 속도를 높였습니다. 이를 위해 작업 중간에 데이터를 캐시로 저장하여, 작업 시간을 단축하였습니다.
4. 데이터 형식: Spark는 다양한 데이터 형식을 지원합니다. 데이터를 처리하기 전에 데이터 형식을 최적화하여 성능을 향상시켰습니다. 가능한 적은 변환을 수행하고 최적의 데이터 형식을 사용하여 작업 시간을 단축하였습니다.
5. 압축: 대용량 데이터를 다룰 때는 데이터 압축을 고려하여 디스크 공간과 데이터 전송 시간을 줄였습니다. 압축을 사용하면 처리 속도가 느려질 수 있으므로 적절한 압축률을 선택하여 작업 시간을 최소화하였습니다.
    1. 어떻게 압축을 하였는가?  
        - 압축은 Apache Spark에서 기본적으로 지원되는 여러 가지 압축 방법 중에서 선택할 수 있습니다. 주로 사용되는 압축 방법으로는 Gzip, Snappy, LZO 등이 있습니다.
        - 저희는 대용량 데이터를 처리하면서 Gzip 압축 방식을 사용하였습니다. Gzip 압축 방식은 압축률이 높아서 디스크 공간과 데이터 전송 시간을 효과적으로 줄일 수 있습니다. 또한, 압축 파일을 읽을 때도 메모리 사용량이 적기 때문에 대용량 데이터 처리에 적합합니다.
        - 압축을 사용할 때는 압축률과 처리 속도 간의 trade-off를 고려해야 합니다. 압축률을 높이면 처리 속도는 느려질 수 있습니다. 따라서 작업 특성에 맞는 적절한 압축률을 선택하여 사용해야 합니다.
        - 압축을 적용하는 방법은 작업 중간 단계에서 데이터를 저장하는 단계에서 압축을 적용하거나, 작업 결과를 저장하는 단계에서 압축을 적용하는 방법이 있습니다. 이 중에서는 작업 결과를 저장하는 단계에서 압축을 적용하는 것이 더욱 효과적입니다. 작업 중간에 압축을 적용하면 처리 속도가 느려지는 문제가 발생할 수 있습니다.
        - 따라서 저희는 작업 결과를 저장하는 단계에서 Gzip 압축을 적용하여 디스크 공간과 데이터 전송 시간을 효과적으로 줄여 4시간의 배치 작업을 1시간으로 단축하였습니다.
6. 쿼리 최적화: Spark는 SQL 쿼리를 실행하는 데 사용됩니다. 쿼리 최적화를 수행하여 쿼리 실행 속도를 향상시켰습니다. 이를 위해 적절한 인덱싱과 조인 방법을 선택하고 쿼리 실행 계획을 확인하여 최적화하였습니다.
7. 코드 최적화: Spark는 Scala, Java, Python 및 R과 같은 언어를 지원합니다. 코드 최적화를 수행하여 불필요한 코드를 제거하고 최적화된 코드를 작성하였습니다. 코드를 작성할 때 최적화 및 성능 향상을 고려하여 작성하였습니다.

이러한 튜닝 기법을 적절히 조합하여 작업 시간을 4시간에서 1시간으로 단축할 수 있었습니다. 모든 튜닝 기법을 적용하지 않아도 작업 시간을 단축할 수 있지만, 작업 특성에 따라 적절한 튜닝 기법을 선택하여 성능을 향상시켜야 합니다.